# CÃ¢mara dos Deputados - AnÃ¡lise de Dados

Este projeto implementa um pipeline de ETL (Extract, Transform, Load) que coleta dados da API da CÃ¢mara dos Deputados, transforma os dados e os carrega em um banco de dados PostgreSQL para anÃ¡lise posterior.

## ğŸ“‹ Requisitos

- Python 3.10+
- Docker e Docker Compose
- PostgreSQL

## ğŸ”§ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

Crie um arquivo `.env` na raiz do projeto com as seguintes variÃ¡veis:

```
# ConfiguraÃ§Ã£o do banco de dados
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=camara_analytics
DATABASE_URL=postgresql://postgres:postgres@db:5432/camara_analytics
```

### InstalaÃ§Ã£o Local (sem Docker)

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/heitorfe/analytics-camara.git
cd analytics-camara
```

2. Crie um ambiente virtual e instale as dependÃªncias:
```bash
python -m venv .venv
source .venv/bin/activate  # No Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

3. Configure o banco de dados PostgreSQL localmente e execute:
```bash
python -m app.database.create_tables
```

### InstalaÃ§Ã£o com Docker

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/seu-usuario/analytics-camara.git
cd analytics-camara
```

2. Inicie os containers:
```bash
docker-compose up -d
```

3. Inicialize o banco de dados e execute a primeira ingestÃ£o:
```bash
docker-compose exec app bash -c "./docker-entrypoint.sh init-db"
```

## ğŸš€ Executando o ETL

### Modos de IngestÃ£o

O projeto suporta dois modos de ingestÃ£o:

- **Full**: Realiza uma ingestÃ£o completa dos dados, substituindo os dados existentes.
- **Incremental**: Realiza uma ingestÃ£o apenas dos dados novos, preservando os dados existentes.

### Entidades DisponÃ­veis

- **deputados**: InformaÃ§Ãµes bÃ¡sicas sobre os deputados
- **votacoes**: SessÃµes de votaÃ§Ã£o na CÃ¢mara
- **votos**: Votos individuais dos deputados em cada votaÃ§Ã£o
- **all**: Todas as entidades acima

### Executando Localmente

```bash
# IngestÃ£o full de todas as entidades
python -m app.ingestion.cron_etl --mode full --entity all

# IngestÃ£o incremental de uma entidade especÃ­fica
python -m app.ingestion.cron_etl --mode incremental --entity votacoes

# IngestÃ£o com intervalo de datas especÃ­fico
python -m app.ingestion.cron_etl --mode full --entity votacoes --start-date 2023-01-01 --end-date 2023-01-31

# IngestÃ£o dos Ãºltimos N dias
python -m app.ingestion.cron_etl --mode incremental --entity all --days 7
```

### Executando com Docker

```bash
# IngestÃ£o full de todas as entidades
docker-compose exec app bash -c "python -m app.ingestion.cron_etl --mode full --entity all"

# IngestÃ£o incremental de uma entidade especÃ­fica
docker-compose exec app bash -c "python -m app.ingestion.cron_etl --mode incremental --entity votacoes"
```

## â±ï¸ Agendamento de Tarefas

O projeto estÃ¡ configurado para executar as seguintes tarefas automaticamente:

- **Diariamente Ã s 2:00**: ExecuÃ§Ã£o incremental para todas as entidades
- **Aos domingos Ã s 3:00**: ExecuÃ§Ã£o completa para todas as entidades

VocÃª pode modificar o agendamento editando o arquivo `crontab` na raiz do projeto.

## ğŸ“Š Estrutura de Dados

### Datasets Brutos

Os dados brutos sÃ£o armazenados no diretÃ³rio `data/raw` nos seguintes arquivos:

- `deputados.parquet`: InformaÃ§Ãµes bÃ¡sicas dos deputados
- `detalhes_deputados.parquet`: InformaÃ§Ãµes detalhadas dos deputados
- `votacoes.parquet`: SessÃµes de votaÃ§Ã£o
- `votos.parquet`: Votos individuais dos deputados

### Datasets Processados

Os dados transformados sÃ£o armazenados no diretÃ³rio `data/processed`.

### Banco de Dados

A estrutura do banco de dados estÃ¡ definida no arquivo `app/database/DDL.sql` e inclui as seguintes tabelas:

- `deputados`: InformaÃ§Ãµes sobre os deputados
- `votacoes`: SessÃµes de votaÃ§Ã£o
- `votos`: Votos dos deputados nas sessÃµes

## ğŸ” Acesso aos Dados

VocÃª pode acessar os dados do PostgreSQL usando qualquer cliente SQL:

```bash
# Acesso direto via psql (local)
psql -h localhost -U postgres -d camara_analytics

# Acesso via Docker
docker-compose exec db psql -U postgres -d camara_analytics
```

## ğŸ“ Logging

Os logs do ETL sÃ£o armazenados no diretÃ³rio `logs/` e podem ser visualizados para acompanhar o progresso das ingestÃµes e diagnosticar problemas.

## ğŸ› ï¸ Desenvolvimento

### Estrutura do Projeto

```
analytics-camara/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ config.py               # ConfiguraÃ§Ãµes gerais
â”‚   â”œâ”€â”€ database/               # ConfiguraÃ§Ã£o do banco de dados
â”‚   â”‚   â”œâ”€â”€ DDL.sql             # Schema do banco
â”‚   â”‚   â”œâ”€â”€ models.py           # Modelos SQLAlchemy
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ ingestion/              # Pipeline de ETL
â”‚   â”‚   â”œâ”€â”€ api.py              # FunÃ§Ãµes de API
â”‚   â”‚   â”œâ”€â”€ extract.py          # Tarefas de extraÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ transform_tasks.py  # Tarefas de transformaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ load.py             # Tarefas de carregamento
â”‚   â”‚   â”œâ”€â”€ flow.py             # Fluxos Prefect
â”‚   â”‚   â”œâ”€â”€ cron_etl.py         # Script para execuÃ§Ã£o agendada
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ models/                 # Modelos de dados
â”œâ”€â”€ data/                       # Armazenamento de dados
â”‚   â”œâ”€â”€ raw/                    # Dados brutos
â”‚   â””â”€â”€ processed/              # Dados processados
â”œâ”€â”€ logs/                       # Logs de execuÃ§Ã£o
â”œâ”€â”€ notebooks/                  # Notebooks de anÃ¡lise
â”œâ”€â”€ docker-compose.yml          # ConfiguraÃ§Ã£o do Docker
â”œâ”€â”€ Dockerfile                  # ConfiguraÃ§Ã£o da imagem
â”œâ”€â”€ crontab                     # ConfiguraÃ§Ã£o de agendamento
â”œâ”€â”€ requirements.txt            # DependÃªncias
â””â”€â”€ README.md                   # Este arquivo
```